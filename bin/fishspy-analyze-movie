#!/usr/bin/python

import os
import sys
import subprocess
import json
import csv
import math
import numpy as np
import h5py
import scipy.ndimage as nd
from scipy.ndimage import gaussian_filter, maximum_filter1d, minimum_filter1d
from scipy.misc import toimage
from PIL import Image, ImageDraw, ImageFont

dark_fish_percentile = 3
fish_blur_sigmas = 1
centroid_median_span = 2

light_toggle_threshold = 20
abs_tail_delta_threshold = 20
abs_tail_offset_threshold = 30

avg_position_bounds = (0.4, 0.85)

num_position_bins = 5

def process_frame(img, tmp_img1, tmp_img2, tmp_img3, debug_frame_sink=None):
    """Process frame image, returning (brightness, tail_position) pair.

       img is RGB packed array with shape (H, W, 3) assumed to be
       grayscale data and MAY be destructively mutated by this
       processing.

       tmp_img1 and tmp_img2 are arrays of uint8 type and (H, W)
       shape used for intermediate calculations.

       tmp_imt3 is array of bool type and (H, W) shape used for
       intermediate calculations.

       debug_frame_sink must be a function accepting the same array
       input which will be modified to display debug information. A
       value of None (default) will skip production of debug data.

    """
    img_rgb = img
    img_g = img_rgb[:,:,0]
    H, W = img_g.shape

    img_max = tmp_img1
    img_dif = tmp_img2
    mask = tmp_img3

    max_window = 11
    mask_thresh = 20
    maximum_filter1d(img_g, max_window, 0, output=img_max)
    np.subtract(img_max, img_g, out=img_dif)
    np.greater(img_dif, mask_thresh, out=mask)

    img_brightness = int(np.sum(img_g) / ( W * H ))
    
    # find the "heights" i.e. centers of mass in Y axis of dark pixels
    x_heights = (np.sum((mask * np.array(range(img_g.shape[0]))[:,None]), axis=0) / np.sum(mask, axis=0))

    tail_slc = slice( int(W*avg_position_bounds[0]), int(W*avg_position_bounds[1]) )
    tail_position = int(np.sum( x_heights[tail_slc] ) / (tail_slc.stop - tail_slc.start))

    position_bins = []
    for b in range(num_position_bins):
        bin_slc = slice( int(W*b/num_position_bins), int(W*(b+1)/num_position_bins) )
        position_bins.append( np.sum( x_heights[bin_slc] ).astype(np.uint16) / (bin_slc.stop - bin_slc.start) )
    
    # illustrate the analysis decisions in an output movie frame
    if debug_frame_sink is not None:
        img_rgb[:,:,2] *= (1 - mask)
        img_rgb[:,:,2] += mask * 255
        for x in range(int(W*avg_position_bounds[0]), int(W*avg_position_bounds[1])):
            img_rgb[x_heights[x], x, 0] = 255
        debug_frame_sink(img_rgb)
    
    return img_brightness, tail_position, position_bins, x_heights

def main(moviename):

    # this produces a JSON metadata document about the movie on standard output
    probecmd = [
        'ffprobe',
        '-i', moviename,
        '-show_streams',
        '-of', 'json'
    ]

    # go ahead and get the movie metadata
    probe_pipe = subprocess.Popen(probecmd, stdout = subprocess.PIPE, bufsize=1024**2)
    probe_pipe.wait()
    doc = probe_pipe.stdout.read()
    del probe_pipe

    meta = json.loads(doc)
    del doc

    assert len(meta['streams']) == 1
    
    meta = meta['streams'][0]
    shape =  meta['height'], meta['width']
    nbframes = int(meta['nb_frames'])

    frame_nbytes = shape[0] * shape[1] * 3
    
    # this generates a stream of raw video pixels to standard output
    readcmd = [
        'ffmpeg',
        '-i', moviename,
        '-f', 'image2pipe', '-pix_fmt', 'rgb24',
        '-vcodec', 'rawvideo', '-'
    ]

    # this accepts a stream of raw video pixels on standard input
    writecmd = [
        'ffmpeg',
        '-y', # clobber
        '-f', 'rawvideo',
        '-s', '%dx%d' % (shape[1], shape[0]),
        '-pix_fmt', 'rgb24',
        '-r', meta['r_frame_rate'],
        '-i', '-',
        '-an',
        '-vcodec', 'libx264',
        '-pix_fmt', 'yuv420p',
        '-x264opts', 'crf=31:bframes=5',
        'movie_debug.m4v'
    ]

    # setup the analysis output streams
    csvwriter1 = csv.writer(open('movie_events.csv', 'w'))
    csvwriter1.writerow( ('frameno','avg. brightness','avg. tailpos','avg. brightness delta','avg. tailpos delta','comment') )

    csvwriter2 = csv.writer(open('movie_frame_measures.csv', 'w'))
    csvwriter2.writerow( ('frameno','avg. brightness') + tuple([ 'position bin %d' % b for b in range(num_position_bins) ]) )

    if os.getenv('FISHSPY_HDF5', 'false').lower() == 'true':
        h5file = h5py.File('movie_frame_measures.hdf5', 'w')
        h5file.attrs['src_movie'] = moviename
        h5file.attrs['X'] = shape[1]
        h5file.attrs['Y'] = shape[0]
        h5file.attrs['nframes'] = nbframes
        h5d_brightness = h5file.create_dataset('brightness', (nbframes,), dtype=np.uint8, chunks=(min(nbframes,1000),), compression='gzip')
        h5d_x_heights = h5file.create_dataset('positions', (nbframes, shape[1]), dtype=np.uint16, chunks=(min(nbframes,1024), shape[1]), compression='gzip')
    else:
        h5file = None
        
    # setup the image buffer we'll use for each frame
    in_img = np.zeros(shape + (3,), dtype='uint8')
    in_buffer = np.getbuffer(in_img)

    # start the input movie decoder
    in_pipe = subprocess.Popen(readcmd, stdout=subprocess.PIPE, bufsize=frame_nbytes*24)

    t = 0

    prev_frame = None
    idle_tail_positions = []
    idle_tail_position = None
    starting_brightness_levels = []
    starting_brightness_level = None
    brightness = None
    avg_position = None
    position_bins = None
    note = ''
    light_on = False
    light_on_cnt = 0
    light_on_t = 0
    light_on_dur = None

    font = ImageFont.truetype('FreeSans.ttf', 16)

    def debug_movie_sink(f):
        #out_pipe.stdin.write(f.tobytes())
        if brightness is not None:
            #f[avg_position,:,0] = 255
            #f[avg_position,:,1] = 0
            #f[avg_position,:,2] = 255
            img = toimage(f)
            draw = ImageDraw.Draw(img)
            draw.text((0, 0), "Bright: %.3d" % brightness, (255,255,255), font=font)
            draw.text((0, 25), "Position: %.3d" % avg_position, (255,255,255), font=font)
            light_color = (0, 255, 0)
            if light_on_t > 0:
                light_t = (t - light_on_t)
                if light_on_dur is not None and (light_t > (light_on_dur/2)):
                    light_color = (255, 0, 0)
                light_t = '%.3d' % light_t
            else:
                light_t = ''
                light_color = (128, 128, 128)
            draw.text(
                (0, 50),
                #"Light %s event %d %s" % (light_on and 'ON' or 'off', light_on_cnt, light_t),
                "Light %s event %d" % (light_on and 'ON' or 'off', light_on_cnt),
                light_color,
                font=font
            )
            draw.text((0, 75), note, (255,255,255), font=font)
        else:
            img = toimage(f)
        out_pipe.stdin.write(img.tobytes())
    
    # conditionally start debug movie output encoder
    if os.getenv('DEBUG_MOVIE', 'false').lower() == 'true':
        out_pipe = subprocess.Popen(writecmd, stdin=subprocess.PIPE, bufsize=frame_nbytes*24)
        sink = debug_movie_sink
    else:
        out_pipe = None
        sink = None

    tmp_img1 = np.zeros(shape, dtype=np.uint8)
    tmp_img2 = np.zeros(shape, dtype=np.uint8)
    tmp_img3 = np.zeros(shape, dtype=np.bool)
        
    # process every input frame
    while t < nbframes:
        # get raw pixels from input decoder and stuff into image buffer
        in_pipe.stdout.readinto(in_buffer)

        brightness, avg_position, position_bins, x_heights = process_frame(
            in_img,
            tmp_img1=tmp_img1,
            tmp_img2=tmp_img2,
            tmp_img3=tmp_img3,
            debug_frame_sink=sink
        )
        if h5file is not None:
            h5d_brightness[t] = brightness
            h5d_x_heights[t,:] = x_heights

        # build up a baseline idle tail position
        if t < 100:
            idle_tail_positions.append(avg_position)
            starting_brightness_levels.append(brightness)
        elif t == 100:
            idle_tail_position = sum(idle_tail_positions) / 100
            starting_brightness_level = sum(starting_brightness_levels) / 100
        
        note = []
        if t >= 100:
            # comparisons to baseline
            if abs(avg_position - idle_tail_position) > abs_tail_offset_threshold:
                note.append('tail bent')
            if (brightness - starting_brightness_level) > (0.5 * light_toggle_threshold) and not light_on:
                light_on_cnt += 1
                light_on_t = t
                note.append('light turns on %d' % light_on_cnt)
                light_on = True
            elif (brightness - starting_brightness_level) < (0.5 * light_toggle_threshold) and light_on:
                note.append('light turns off %d' % light_on_cnt)
                light_on = False
                light_on_dur = t - light_on_t
                light_on_t = 0
                
        if prev_frame:
            # comparisons to previous frame
            if brightness - prev_frame[1] > light_toggle_threshold and not light_on:
                light_on_cnt += 1
                light_on_t = t
                note.append('light turns on %d' % light_on_cnt)
                light_on = True
            elif prev_frame[1] - brightness > light_toggle_threshold and light_on:
                note.append('light turns off %d' % light_on_cnt)
                light_on = False
                light_on_dur = t - light_on_t
                light_on_t = 0
            if (abs(avg_position - prev_frame[2]) > abs_tail_delta_threshold):
                note.append('tail fast')

        note = ','.join(note)

        # conditionally log the frame results only if an interesting condition is noted
        if note:
            csvwriter1.writerow((t, brightness, avg_position, brightness - prev_frame[1], avg_position - prev_frame[2], note))

        csvwriter2.writerow( (t, brightness) + tuple(position_bins) )
            
        prev_frame = (t, brightness, avg_position, note)
        t += 1

    if out_pipe:
        out_pipe.stdin.close()

    in_pipe.wait()
        
    if out_pipe:
        out_pipe.wait()

    if h5file is not None:
        h5file.close()
    
if __name__ == '__main__':
    moviename = sys.argv[1]
    exit(main(moviename))

